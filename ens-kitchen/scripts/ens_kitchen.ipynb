{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyKCCb9cT-mF"
      },
      "source": [
        "# ens_kitchen notebook\n",
        "\n",
        "Jupyter notebook for data extraction and processing for ENS Endowment data update & analysis. **Execution is on Colab** (not locally).\n",
        "\n",
        "Sections:\n",
        "1. **setup:** done in the first section in order to have proper config for the whole nobtebook.\n",
        "2. **data collection:** section used for collecting data for the jt kitchen.\n",
        "    1. **prices:** fetch prices for ENS portfolio relevant tokens.\n",
        "    2. **sf ens financials:** fetch all ens financial transactions.\n",
        "    3. **ens dao holdings:** collect ens dao holdings along all DAO wallets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LigVHewUQpM",
        "outputId": "b4ca3f0b-ed7e-475c-8f56-bd54f46d4933"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Setup all the required variables & logic for the notebook.\n",
        "\"\"\"\n",
        "\n",
        "# ==============================================\n",
        "#  Install Required Packages (go first to click on pop up quickly)\n",
        "# ==============================================\n",
        "\n",
        "# Google authentication libraries\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "# ==============================================\n",
        "#  Install Required Packages\n",
        "# ==============================================\n",
        "\n",
        "# user-built packages to run in the colab\n",
        "GITHUB_TOKEN = \"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\"\n",
        "BRANCH = \"main\"\n",
        "! pip install git+https://{GITHUB_TOKEN}@github.com/tom4s-lt/kpk-kitchens.git@{BRANCH}\n",
        "\n",
        "# ==============================================\n",
        "#  Import Required Libraries\n",
        "# ==============================================\n",
        "\n",
        "# user-built config class and functions\n",
        "from kpk_kitchens.config import ENSConfig\n",
        "from kpk_kitchens.utils import etl_gen_df_from_gsheet, gecko_get_price_historical, spice_query_id\n",
        "\n",
        "# Other libraries\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "from typing import Optional, Dict, Any, List\n",
        "\n",
        "# ==============================================\n",
        "#  Initialize script variables & params\n",
        "# ==============================================\n",
        "\n",
        "# google credentials & client\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Create the data directory\n",
        "os.makedirs(ENSConfig.DATA_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# data collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fetches prices for ens portfolio relevant tokens from CoinGecko.\n",
        "\n",
        "args:\n",
        "    none\n",
        "\n",
        "returns:\n",
        "    prices.csv: prices for all assets in the portfolio\n",
        "\"\"\"\n",
        "\n",
        "# Fetch assets from Google Sheet\n",
        "json_lk_assets = etl_gen_df_from_gsheet(gc, ENSConfig.WORKBOOK_URL, ENSConfig.LK_ASSETS)\n",
        "\n",
        "# filter - only ENS assets\n",
        "json_ens_assets = [\n",
        "    asset for asset in json_lk_assets\n",
        "    if asset.get(\"company\") == \"ENS\"\n",
        "]\n",
        "\n",
        "# Separate stablecoins and non-stablecoins - only symbol_level_0\n",
        "stablecoins = [\n",
        "    asset for asset in json_ens_assets\n",
        "    if (asset.get(\"type_market\") == \"stablecoin\") and (asset.get(\"type_level\") == \"level_0\")\n",
        "]\n",
        "\n",
        "non_stablecoins = [\n",
        "    asset for asset in json_ens_assets\n",
        "    if (asset.get(\"type_market\") != \"stablecoin\") and (asset.get(\"type_level\") == \"level_0\")\n",
        "]\n",
        "\n",
        "print(f\"Found {len(stablecoins)} stablecoins and {len(non_stablecoins)} non-stablecoins\")\n",
        "\n",
        "print(\"\\nOnly level_0/underlying is fetched because that's waht's prices in the reporting\")\n",
        "\n",
        "# Filter duplicates on symbol_level_0 for non_stablecoins\n",
        "non_stablecoins = list({\n",
        "    asset.get(\"symbol_level_0\", \"\"): asset \n",
        "    for asset in non_stablecoins \n",
        "    if asset.get(\"symbol_level_0\", \"\")\n",
        "}.values())\n",
        "\n",
        "# Fetch and process price data for non-stablecoin assets\n",
        "price_data = []\n",
        "for asset in non_stablecoins:\n",
        "    print(f\"Fetching data for {asset['symbol']}...\")\n",
        "    \n",
        "    gecko_hist_data = gecko_get_price_historical(\n",
        "        base_url=ENSConfig.COINGECKO_API_BASE_URL,\n",
        "        asset_id=asset['id_gecko'],\n",
        "        api_key=ENSConfig.COINGECKO_API_KEY,\n",
        "        max_retries=ENSConfig.MAX_RETRIES,\n",
        "        retry_delay=ENSConfig.RETRY_DELAY,\n",
        "        timeout=ENSConfig.DEFAULT_TIMEOUT,\n",
        "        # params is function default - 365 days max with free key\n",
        "        headers={\n",
        "            'accept': 'application/json',\n",
        "            'x-cg-demo-api-key': ENSConfig.COINGECKO_API_KEY\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if gecko_hist_data:\n",
        "        # Create DataFrame for current asset\n",
        "        df = pd.DataFrame(gecko_hist_data['prices'], columns=['ts', 'price'])\n",
        "        df['id_gecko'] = asset['id_gecko']\n",
        "        df['symbol'] = asset['symbol']\n",
        "        price_data.append(df)\n",
        "        print(f\"Successfully fetched data for {asset['symbol']}\")\n",
        "\n",
        "    time.sleep(3)  # Rate limiting\n",
        "\n",
        "print(\"\\nPrice data collection complete\")\n",
        "\n",
        "# Process price data\n",
        "print(\"\\nProcessing price data...\")\n",
        "df_prices = pd.concat(price_data)\n",
        "df_prices['date'] = pd.to_datetime(df_prices['ts'], unit='ms')\n",
        "\n",
        "# Resample to daily frequency and calculate mean prices\n",
        "df_prices = (df_prices\n",
        "    .groupby(['symbol', 'id_gecko'])\n",
        "    .resample('D', on='date')\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    [['date', 'symbol', 'id_gecko', 'price']]  # Drop ts\n",
        "    .sort_values('date', ascending=False)\n",
        ")\n",
        "\n",
        "print(\"\\nPrice data processing complete\")\n",
        "\n",
        "# Add stablecoin data with price=1\n",
        "if stablecoins:\n",
        "    print(\"\\nAdding stablecoin data...\")\n",
        "    # Get unique dates from the price data\n",
        "    dates = df_prices['date'].unique()\n",
        "\n",
        "    # Create stablecoin records\n",
        "    stablecoin_data = []\n",
        "    for asset in stablecoins:\n",
        "        for date in dates:\n",
        "            stablecoin_data.append({\n",
        "                'date': date,\n",
        "                'symbol': asset['symbol'],\n",
        "                'id_gecko': asset['id_gecko'],\n",
        "                'price': 1.0\n",
        "            })\n",
        "\n",
        "    # Convert to DataFrame and append to price data\n",
        "    df_stablecoins = pd.DataFrame(stablecoin_data)\n",
        "    df_prices = pd.concat([df_prices, df_stablecoins], ignore_index=True)\n",
        "    df_prices = df_prices.sort_values('date', ascending=False)\n",
        "\n",
        "print(\"\\nStablecoin prices complete\")\n",
        "\n",
        "# Export results\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.PRICES_CSV}...\")\n",
        "df_prices.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.PRICES_CSV}\", index=False)\n",
        "print(\"\\nExport complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## sf ens financials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fetches ENS financial data from extractor query <- SF dune queries\n",
        "Might add more metadata to create different aggregations but not necessary for now.\n",
        "    - wallel labels that come from lk_addresses in the kitchen\n",
        "\n",
        "args:\n",
        "    none\n",
        "\n",
        "returns:\n",
        "    financials.csv: historical financial data for ENS\n",
        "\"\"\"\n",
        "\n",
        "# Get data from dune query\n",
        "df_financials = spice_query_id(\n",
        "    query_id=ENSConfig.DUNE_ID_SF_EXTRACT_ENS_FINANCIALS,\n",
        "    api_key=ENSConfig.DUNE_API_KEY,\n",
        "    refresh=True,\n",
        ")\n",
        "\n",
        "print(\"Financial data obtained from Dune.\")\n",
        "\n",
        "# period/year data comes with hh:mm:ss:... - convert to date/year only\n",
        "df_financials['year'] = pd.to_datetime(df_financials['year'])\n",
        "df_financials['year'] = df_financials['year'].dt.year\n",
        "\n",
        "df_financials['period'] = pd.to_datetime(df_financials['period'])\n",
        "df_financials['period'] = df_financials['period'].dt.date\n",
        "\n",
        "# Export results\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.FINANCIALS_CSV}...\")\n",
        "df_financials.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.FINANCIALS_CSV}\", index=False)\n",
        "print(\"\\nExport complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ens dao holdings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fetches ENS DAO (excl. Endowment) holdings extractor query <- SF dune queries\n",
        "\n",
        "args:\n",
        "    query params: addresses coming from lk_Addresses\n",
        "\n",
        "returns:\n",
        "    financials.csv: historical financial data for ENS\n",
        "\"\"\"\n",
        "\n",
        "# Fetch addresses from Google Sheet\n",
        "json_lk_addresses = etl_gen_df_from_gsheet(gc, ENSConfig.WORKBOOK_URL, 'lk_addresses')\n",
        "\n",
        "# get only the addresses - remember to lower for correct matching later\n",
        "ens_addresses = [\n",
        "    address.get('address').lower() for address in json_lk_addresses\n",
        "]\n",
        "\n",
        "ens_addresses = \",\".join(ens_addresses)\n",
        "\n",
        "# create params for query\n",
        "parameters = {\n",
        "    'ens_addresses': ens_addresses\n",
        "}\n",
        "\n",
        "# Get data from dune query\n",
        "df_holdings = spice_query_id(\n",
        "    query_id=ENSConfig.DUNE_ID_EXTRACT_ENS_DAO_HOLDINGS,\n",
        "    api_key=ENSConfig.DUNE_API_KEY,\n",
        "    parameters=parameters,\n",
        "    refresh=True,\n",
        ")\n",
        "\n",
        "print(\"Holdings data obtained from Dune.\")\n",
        "\n",
        "# period data comes with hh:mm:ss:... - convert to date only\n",
        "df_holdings['day'] = pd.to_datetime(df_holdings['day'])\n",
        "df_holdings['day'] = df_holdings['day'].dt.date\n",
        "\n",
        "# Export results\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.HOLDINGS_CSV}...\")\n",
        "df_holdings.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.HOLDINGS_CSV}\", index=False)\n",
        "print(\"\\nExport complete!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "kpk-general",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
