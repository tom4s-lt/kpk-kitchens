{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyKCCb9cT-mF"
      },
      "source": [
        "# ens_kitchen\n",
        "\n",
        "Jupyter notebook for data extraction and processing for ENS Endowment data update & analysis. **Execution is on Colab** (not locally) unless [st] (standalone).\n",
        "\n",
        "1. **setup:** done in the first section in order to have proper config for the whole nobtebook.\n",
        "<br>\n",
        "\n",
        "2. **data collection:** section used for collecting data for the jt kitchen.\n",
        "    1. **prices:** fetch prices for ENS portfolio relevant tokens.\n",
        "    2. **sf ens financials:** fetch all ens financial transactions.\n",
        "    3. **ens dao holdings:** fetch ens dao holdings along all DAO wallets.\n",
        "    4. **vaults.fyi:** fetch allocation metrics for monitoring.\n",
        "3. **monitoring:** section used for monitoring and general analysis.\n",
        "    1. **vaults.fyi:** monitoring of yield strategies for decision-making.\n",
        "4. **other utils:** section used for other utilities.\n",
        "    1. **cow swap order exec:** get Cow Swap quotes (using their API) for a different trade sizes between two tokens.\n",
        "    2. **rb underlying:** get the underlying amount of tokens using web3.py for reward bearing assets at a specific block."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNceggc7DPaQ"
      },
      "source": [
        "# setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LigVHewUQpM",
        "outputId": "842dfce8-e672-4e1c-ff3c-c508b972d86e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://****@github.com/tom4s-lt/kpk-kitchens.git@main\n",
            "  Cloning https://****@github.com/tom4s-lt/kpk-kitchens.git (to revision main) to /tmp/pip-req-build-9g7lszbq\n",
            "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/tom4s-lt/kpk-kitchens.git' /tmp/pip-req-build-9g7lszbq\n",
            "  Resolved https://****@github.com/tom4s-lt/kpk-kitchens.git to commit c53b536ccd0b34ba9430119ef75170a44df2d843\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from kpk_kitchens==0.1.1) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kpk_kitchens==0.1.1) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from kpk_kitchens==0.1.1) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from kpk_kitchens==0.1.1) (0.13.2)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (from kpk_kitchens==0.1.1) (6.2.1)\n",
            "Collecting dune_spice (from kpk_kitchens==0.1.1)\n",
            "  Downloading dune_spice-0.2.7-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (from kpk_kitchens==0.1.1) (1.25.0)\n",
            "Collecting vaultsfyi (from kpk_kitchens==0.1.1)\n",
            "  Downloading vaultsfyi-1.1.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp>=3.9.5 in /usr/local/lib/python3.11/dist-packages (from dune_spice->kpk_kitchens==0.1.1) (3.12.14)\n",
            "Requirement already satisfied: rich>=13.3.3 in /usr/local/lib/python3.11/dist-packages (from dune_spice->kpk_kitchens==0.1.1) (13.9.4)\n",
            "Collecting rich-argparse>=1.5.2 (from dune_spice->kpk_kitchens==0.1.1)\n",
            "  Downloading rich_argparse-1.7.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kpk_kitchens==0.1.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kpk_kitchens==0.1.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kpk_kitchens==0.1.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kpk_kitchens==0.1.1) (2025.7.14)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread->kpk_kitchens==0.1.1) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread->kpk_kitchens==0.1.1) (1.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->kpk_kitchens==0.1.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->kpk_kitchens==0.1.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->kpk_kitchens==0.1.1) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->kpk_kitchens==0.1.1) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib->kpk_kitchens==0.1.1) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->kpk_kitchens==0.1.1) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->kpk_kitchens==0.1.1) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->kpk_kitchens==0.1.1) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->kpk_kitchens==0.1.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->kpk_kitchens==0.1.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->kpk_kitchens==0.1.1) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.5->dune_spice->kpk_kitchens==0.1.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.5->dune_spice->kpk_kitchens==0.1.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.5->dune_spice->kpk_kitchens==0.1.1) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.5->dune_spice->kpk_kitchens==0.1.1) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.5->dune_spice->kpk_kitchens==0.1.1) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.5->dune_spice->kpk_kitchens==0.1.1) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.9.5->dune_spice->kpk_kitchens==0.1.1) (1.20.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread->kpk_kitchens==0.1.1) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread->kpk_kitchens==0.1.1) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread->kpk_kitchens==0.1.1) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread->kpk_kitchens==0.1.1) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->kpk_kitchens==0.1.1) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.3.3->dune_spice->kpk_kitchens==0.1.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.3.3->dune_spice->kpk_kitchens==0.1.1) (2.19.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.9.5->dune_spice->kpk_kitchens==0.1.1) (4.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.3->dune_spice->kpk_kitchens==0.1.1) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread->kpk_kitchens==0.1.1) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread->kpk_kitchens==0.1.1) (3.3.1)\n",
            "Downloading dune_spice-0.2.7-py3-none-any.whl (23 kB)\n",
            "Downloading vaultsfyi-1.1.0-py3-none-any.whl (8.5 kB)\n",
            "Downloading rich_argparse-1.7.1-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: kpk_kitchens\n",
            "  Building wheel for kpk_kitchens (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kpk_kitchens: filename=kpk_kitchens-0.1.1-py3-none-any.whl size=5673 sha256=8c07799267a2eacfd777193bff392f07a99872d1d0b9fe499f917fa2e35330c8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x54fwtkg/wheels/70/78/1f/a3817b10f7b263cc997f52149699653337638b01717388c103\n",
            "Successfully built kpk_kitchens\n",
            "Installing collected packages: vaultsfyi, rich-argparse, dune_spice, kpk_kitchens\n",
            "Successfully installed dune_spice-0.2.7 kpk_kitchens-0.1.1 rich-argparse-1.7.1 vaultsfyi-1.1.0\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Setup all the required variables & logic for the notebook.\n",
        "\"\"\"\n",
        "\n",
        "# ==============================================\n",
        "# Install required packages\n",
        "# ==============================================\n",
        "\n",
        "# kpk_kitchens - user-built package to run in the colab\n",
        "GITHUB_TOKEN = \"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\"\n",
        "BRANCH = \"main\"\n",
        "! pip install git+https://{GITHUB_TOKEN}@github.com/tom4s-lt/kpk-kitchens.git@{BRANCH}\n",
        "\n",
        "# ==============================================\n",
        "# Import Required Libraries\n",
        "# ==============================================\n",
        "\n",
        "# user-built config class and functions\n",
        "from kpk_kitchens.config import ENSConfig\n",
        "from kpk_kitchens import utils as utils  # import all functions.show().sh......\n",
        "\n",
        "# Google authentication libraries\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "# Other libraries\n",
        "from vaultsfyi import VaultsSdk\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# ==============================================\n",
        "#  Initialize script variables & params\n",
        "# ==============================================\n",
        "\n",
        "# google authentication, credentials & client\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Create the data directory\n",
        "os.makedirs(ENSConfig.DATA_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUrdRig4DPaR"
      },
      "source": [
        "# data collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7az2fYFDPaR"
      },
      "source": [
        "## prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8r2e7CIDPaS"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fetches prices for ens portfolio relevant tokens from CoinGecko.\n",
        "\n",
        "args:\n",
        "    none\n",
        "\n",
        "returns:\n",
        "    prices.csv: prices for all assets in the portfolio\n",
        "\"\"\"\n",
        "\n",
        "# Fetch assets from Google Sheet\n",
        "json_lk_assets = utils.etl_gen_df_from_gsheet(gc, ENSConfig.WORKBOOK_URL, ENSConfig.LK_ASSETS_TAB)\n",
        "\n",
        "# filter - only ENS assets\n",
        "json_ens_assets = [\n",
        "    asset for asset in json_lk_assets\n",
        "    if asset.get(\"company\") == \"ENS\"\n",
        "]\n",
        "\n",
        "# Separate stablecoins and non-stablecoins - only symbol_level_0\n",
        "stablecoins = [\n",
        "    asset for asset in json_ens_assets\n",
        "    if (asset.get(\"type_market\") == \"stablecoin\") and (asset.get(\"type_level\") == 0)\n",
        "]\n",
        "\n",
        "non_stablecoins = [\n",
        "    asset for asset in json_ens_assets\n",
        "    if (asset.get(\"type_market\") != \"stablecoin\") and (asset.get(\"type_level\") == 0)\n",
        "]\n",
        "\n",
        "print(f\"Found {len(stablecoins)} stablecoins and {len(non_stablecoins)} non-stablecoins\")\n",
        "\n",
        "print(\"\\nOnly level_0/underlying is fetched because that's waht's prices in the reporting\")\n",
        "\n",
        "# Filter duplicates on symbol_level_0 for non_stablecoins\n",
        "non_stablecoins = list({\n",
        "    asset.get(\"symbol_level_0\", \"\"): asset\n",
        "    for asset in non_stablecoins\n",
        "    if asset.get(\"symbol_level_0\", \"\")\n",
        "}.values())\n",
        "\n",
        "# Fetch and process price data for non-stablecoin assets\n",
        "price_data = []\n",
        "for asset in non_stablecoins:\n",
        "    print(f\"Fetching data for {asset['symbol']}...\")\n",
        "\n",
        "    gecko_hist_data = utils.gecko_get_price_historical(\n",
        "        base_url=ENSConfig.COINGECKO_API_BASE_URL,\n",
        "        asset_id=asset['id_gecko'],\n",
        "        api_key=ENSConfig.COINGECKO_API_KEY,\n",
        "        max_retries=ENSConfig.MAX_RETRIES,\n",
        "        retry_delay=ENSConfig.RETRY_DELAY,\n",
        "        timeout=ENSConfig.DEFAULT_TIMEOUT,\n",
        "        # params is function default - 365 days max with free key\n",
        "        headers={\n",
        "            'accept': 'application/json',\n",
        "            'x-cg-demo-api-key': ENSConfig.COINGECKO_API_KEY\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if gecko_hist_data:\n",
        "        # Create DataFrame for current asset\n",
        "        df = pd.DataFrame(gecko_hist_data['prices'], columns=['ts', 'price'])\n",
        "        df['id_gecko'] = asset['id_gecko']\n",
        "        df['symbol'] = asset['symbol']\n",
        "        price_data.append(df)\n",
        "        print(f\"Successfully fetched data for {asset['symbol']}\")\n",
        "\n",
        "    time.sleep(3)  # Rate limiting\n",
        "\n",
        "print(\"\\nPrice data collection complete\")\n",
        "\n",
        "# Process price data\n",
        "print(\"\\nProcessing price data...\")\n",
        "df_prices = pd.concat(price_data)\n",
        "df_prices['date'] = pd.to_datetime(df_prices['ts'], unit='ms')\n",
        "\n",
        "# Resample to daily frequency and calculate mean prices\n",
        "df_prices = (df_prices\n",
        "    .groupby(['symbol', 'id_gecko'])\n",
        "    .resample('D', on='date')\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    [['date', 'symbol', 'id_gecko', 'price']]  # Drop ts\n",
        "    .sort_values('date', ascending=False)\n",
        ")\n",
        "\n",
        "print(\"\\nPrice data processing complete\")\n",
        "\n",
        "# Add stablecoin data with price=1\n",
        "if stablecoins:\n",
        "    print(\"\\nAdding stablecoin data...\")\n",
        "    # Get unique dates from the price data\n",
        "    dates = df_prices['date'].unique()\n",
        "\n",
        "    # Create stablecoin records\n",
        "    stablecoin_data = []\n",
        "    for asset in stablecoins:\n",
        "        for date in dates:\n",
        "            stablecoin_data.append({\n",
        "                'date': date,\n",
        "                'symbol': asset['symbol'],\n",
        "                'id_gecko': asset['id_gecko'],\n",
        "                'price': 1.0\n",
        "            })\n",
        "\n",
        "    # Convert to DataFrame and append to price data\n",
        "    df_stablecoins = pd.DataFrame(stablecoin_data)\n",
        "    df_prices = pd.concat([df_prices, df_stablecoins], ignore_index=True)\n",
        "    df_prices = df_prices.sort_values('date', ascending=False)\n",
        "\n",
        "print(\"\\nStablecoin prices complete\")\n",
        "\n",
        "# Export results\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.PRICES_CSV}...\")\n",
        "df_prices.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.PRICES_CSV}\", index=False)\n",
        "print(\"\\nExport complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agrXUgEnDPaS"
      },
      "source": [
        "## sf ens financials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHK1TZl7DPaT"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fetches ENS financial data from extractor query <- SF dune queries\n",
        "Might add more metadata to create different aggregations but not necessary for now.\n",
        "    - wallel labels that come from lk_addresses in the kitchen\n",
        "\n",
        "args:\n",
        "    token_address: ENS token address - comment in the query to exclude/include by excluding parameters\n",
        "\n",
        "returns:\n",
        "    financials.csv: historical financial data for ENS\n",
        "\"\"\"\n",
        "\n",
        "# create params for query\n",
        "parameters = {\n",
        "    'token_address': ENSConfig.ENS_TOKEN_ADDRESS\n",
        "}\n",
        "\n",
        "# Get data from dune query\n",
        "df_financials = utils.spice_query_id(\n",
        "    query_id=ENSConfig.DUNE_QID_EXTRACT_SF_ENS_FINANCIALS_PER_WALLET,\n",
        "    api_key=ENSConfig.DUNE_API_KEY,\n",
        "    parameters=parameters,\n",
        "    refresh=True,\n",
        ")\n",
        "\n",
        "print(\"Financial data obtained from Dune.\")\n",
        "\n",
        "# period/year data comes with hh:mm:ss:... - convert to date/year only\n",
        "df_financials['year'] = pd.to_datetime(df_financials['year'])\n",
        "df_financials['year'] = df_financials['year'].dt.year\n",
        "\n",
        "df_financials['period'] = pd.to_datetime(df_financials['period'])\n",
        "df_financials['period'] = df_financials['period'].dt.date\n",
        "\n",
        "# Export results\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.FINANCIALS_CSV}...\")\n",
        "df_financials.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.FINANCIALS_CSV}\", index=False)\n",
        "print(\"\\nExport complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DPE2r4zDPaT"
      },
      "source": [
        "## ens dao holdings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPvfkhEUDPaU"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fetches ENS DAO (excl. Endowment) holdings extractor query <- SF dune queries\n",
        "\n",
        "args:\n",
        "    query params: addresses coming from lk_Addresses, custom_date\n",
        "\n",
        "returns:\n",
        "    financials.csv: historical financial data for ENS\n",
        "\"\"\"\n",
        "\n",
        "# Fetch addresses from Google Sheet\n",
        "json_lk_addresses = utils.etl_gen_df_from_gsheet(gc, ENSConfig.WORKBOOK_URL, ENSConfig.LK_ADDRESSES_TAB)\n",
        "\n",
        "# get only the addresses - remember to lower for correct matching later\n",
        "ens_addresses = [\n",
        "    address.get('address').lower() for address in json_lk_addresses\n",
        "]\n",
        "\n",
        "ens_addresses = \",\".join(ens_addresses)\n",
        "\n",
        "# create params for query\n",
        "custom_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
        "parameters = {\n",
        "    'ens_addresses': ens_addresses,\n",
        "    'custom_date': custom_date\n",
        "}\n",
        "\n",
        "# Get data from dune query\n",
        "df_holdings = utils.spice_query_id(\n",
        "    query_id=ENSConfig.DUNE_QID_EXTRACT_ENS_DAO_HOLDINGS,\n",
        "    api_key=ENSConfig.DUNE_API_KEY,\n",
        "    parameters=parameters,\n",
        "    refresh=True,\n",
        ")\n",
        "\n",
        "print(\"Holdings data obtained from Dune.\")\n",
        "\n",
        "# period data comes with hh:mm:ss:... - convert to date only\n",
        "df_holdings['day'] = pd.to_datetime(df_holdings['day'])\n",
        "df_holdings['day'] = df_holdings['day'].dt.date\n",
        "\n",
        "# Export results\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.HOLDINGS_CSV}...\")\n",
        "df_holdings.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.HOLDINGS_CSV}\", index=False)\n",
        "print(\"\\nExport complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbCj9Xj_DQT3"
      },
      "source": [
        "## vaults.fyi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuw1O8GyYgO-"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fetches allowed strategies historical data from vaults.fyi\n",
        "\n",
        "args:\n",
        "    coa: ENS chart of accounts holding data required for getting historical data\n",
        "\n",
        "returns:\n",
        "    vaults_positions.csv: historical yield data for ENS positions & Dataframe\n",
        "\"\"\"\n",
        "\n",
        "# user config - please don't stress the execution button as we might be left without credit\n",
        "client = VaultsSdk(api_key=ENSConfig.VAULTS_FYI_API_KEY)\n",
        "\n",
        "# Fetch chart of accounts from Google Sheet\n",
        "json_lk_coa = utils.etl_gen_df_from_gsheet(gc, ENSConfig.WORKBOOK_URL, 'lk_coa_p')\n",
        "\n",
        "# Save positions data for fetching vaults.fyi\n",
        "json_positions = []\n",
        "\n",
        "for position in range(len(json_lk_coa)):\n",
        "    if (json_lk_coa[position]['vaults'] != '') & (json_lk_coa[position]['vaults'] != 'null'):\n",
        "\n",
        "        json_positions.append(\n",
        "            {\n",
        "                'address': json_lk_coa[position]['vaults'],\n",
        "                'blockchain': json_lk_coa[position]['blockchain'],\n",
        "                'symbol': json_lk_coa[position]['symbol'],\n",
        "                'account_label': json_lk_coa[position]['account_label'],\n",
        "                'account_allocation': json_lk_coa[position]['account_allocation'],\n",
        "            }\n",
        "        )\n",
        "\n",
        "# fetch data from vaults.fyi\n",
        "json_vaults_positions = []\n",
        "\n",
        "for position in range(len(json_positions)):\n",
        "    print(f\"Fetching data for {json_positions[position]['account_label']}\")\n",
        "\n",
        "    r = client.get_vault_historical_data(  # returns a dictionary\n",
        "        network = json_positions[position]['blockchain'].replace('ethereum', 'mainnet'),\n",
        "        vault_address = json_positions[position]['address'],\n",
        "        page = 0,\n",
        "        perPage = 1000,\n",
        "        apyInterval = '1day',\n",
        "        granularity = '1day'\n",
        "    )\n",
        "\n",
        "    for record in r['data']:\n",
        "        json_vaults_positions.append(\n",
        "            {\n",
        "                'timestamp': record['timestamp'],\n",
        "                'position': json_positions[position]['account_label'],\n",
        "                'allocation': json_positions[position]['account_allocation'],\n",
        "                'symbol': json_positions[position]['symbol'],\n",
        "                'tvl_usd': record['tvl']['usd'],\n",
        "                'tvl_native': record['tvl']['native'],\n",
        "                'apy_base': record['apy']['base'],\n",
        "                'apy_reward': record['apy']['reward'],\n",
        "                'apy_total': record['apy']['total'],\n",
        "            }\n",
        "        )\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "print(f\"\\nFinished fetching Vaults data.\")\n",
        "\n",
        "# Create dataframe with all the information & a CSV\n",
        "df_vaults_positions_ = pd.DataFrame.from_records(json_vaults_positions)\n",
        "\n",
        "# Export results\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.VAULTS_POSITIONS_CSV}...\")\n",
        "df_vaults_positions_.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.VAULTS_POSITIONS_CSV}\", index=False)\n",
        "print(\"\\nExport complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d1Cq38ON32l"
      },
      "source": [
        "# monitoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx4eSCOuP7rr"
      },
      "source": [
        "## vaults.fyi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCCNwLkFe2hy",
        "outputId": "2417fd33-1ee1-4cfb-f662-beacf1eb6f28"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_vaults_positions_' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mAnalyze allocation yields using vaults.fyi data\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    df_vaults_positions: with included 1d, 7d, 30d, apy\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# make a copy of the dataframe to keep original\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m df_vaults_positions \u001b[38;5;241m=\u001b[39m \u001b[43mdf_vaults_positions_\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# adjust columns & set index\u001b[39;00m\n\u001b[1;32m     15\u001b[0m df_vaults_positions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_vaults_positions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m], unit \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_vaults_positions_' is not defined"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Analyze allocation yields using vaults.fyi data\n",
        "\n",
        "args:\n",
        "    df_vaults_positions: historical yield data for ENS positions\n",
        "\n",
        "returns:\n",
        "    df_vaults_positions: with included 1d, 7d, 30d, apy\n",
        "\"\"\"\n",
        "\n",
        "# make a copy of the dataframe to keep original\n",
        "df_vaults_positions = df_vaults_positions_.copy()\n",
        "\n",
        "# adjust columns & set index\n",
        "df_vaults_positions['date'] = pd.to_datetime(df_vaults_positions['timestamp'], unit = 's')\n",
        "df_vaults_positions = df_vaults_positions.set_index('date')\n",
        "df_vaults_positions = df_vaults_positions.drop('timestamp', axis = 1)\n",
        "df_vaults_positions = df_vaults_positions.sort_index()\n",
        "\n",
        "# add r+1 for each of the records for each date\n",
        "df_vaults_positions['r1'] = (1 + df_vaults_positions['apy_total']) ** (1/365)\n",
        "\n",
        "# calculate twr for the required windoes\n",
        "for window in [1, 7, 30, 180, 365]:\n",
        "    df_window = df_vaults_positions.groupby(['position', 'allocation', 'symbol']).rolling(window = window).apply(np.prod, raw=True)['r1'].to_frame()\n",
        "    df_window.columns = [f'apy_{window}d']\n",
        "    df_window[f'apy_{window}d'] = df_window[f'apy_{window}d'] ** (365/window) - 1  # normalize to a year and make it APY\n",
        "\n",
        "    df_vaults_positions = df_vaults_positions.merge(df_window, on=['date', 'position', 'allocation', 'symbol'])\n",
        "\n",
        "# calculate 30day volatility\n",
        "df_vol = df_vaults_positions.groupby(['position', 'allocation', 'symbol']).rolling(window=30).std()['apy_1d'].to_frame()\n",
        "df_vol.columns = ['vol_30d']\n",
        "\n",
        "# Merge back into the main dataframe\n",
        "df_vaults_positions = df_vaults_positions.merge(df_vol, on=['date', 'position', 'allocation', 'symbol'])\n",
        "\n",
        "# Save to csv\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.VAULTS_POSITIONS_METRICS_CSV}...\")\n",
        "df_vaults_positions.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.VAULTS_POSITIONS_METRICS_CSV}\", index=False)\n",
        "\n",
        "# Separate into dataframes based on allocation\n",
        "df_vaults_stable = df_vaults_positions.loc[df_vaults_positions['allocation'].str.lower() == 'stable']\n",
        "df_vaults_ether = df_vaults_positions.loc[df_vaults_positions['allocation'].str.lower() == 'ether']\n",
        "\n",
        "# Last date\n",
        "last_date = df_vaults_positions.index.max()\n",
        "\n",
        "# Show data for each\n",
        "float_format = \".4f\"\n",
        "\n",
        "print(\"Stable allocation\")\n",
        "print(\"\")\n",
        "print(tabulate(\n",
        "    df_vaults_stable.loc[df_vaults_stable.index == last_date].reset_index().sort_values('apy_7d', ascending=False)[\n",
        "        ['date', 'symbol', 'position', 'tvl_usd', 'apy_30d', 'apy_7d', 'apy_1d', 'vol_30d', 'apy_180d', 'apy_365d']\n",
        "    ],\n",
        "    headers='keys',\n",
        "    tablefmt='psql',\n",
        "    showindex=False,\n",
        "    floatfmt=float_format\n",
        "))\n",
        "\n",
        "print(\"\\nEther allocation\")\n",
        "print(\"\")\n",
        "print(tabulate(\n",
        "    df_vaults_ether.loc[df_vaults_ether.index == last_date].reset_index().sort_values('apy_7d', ascending=False)[\n",
        "        ['date', 'symbol', 'position', 'tvl_usd', 'apy_30d', 'apy_7d', 'apy_1d', 'vol_30d', 'apy_180d', 'apy_365d']\n",
        "    ],\n",
        "    headers='keys',\n",
        "    tablefmt='psql',\n",
        "    showindex=False,\n",
        "    floatfmt=float_format\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZDP1UqGNI3K",
        "outputId": "3c2123a4-f5eb-4434-868a-053e1aabe3ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Vault        : Savings USDS\n",
            "Protocol     : Sky (collateral vault)\n",
            "Asset        : USDS\n",
            "Network      : mainnet\n",
            "Pool Address : 0xa3931d71877C0E7a3148CB7Eb4463524FEc27fbD\n",
            "Balance      : 22,979,215.2090 USDS\n",
            "Value (USD)  : $24,360,443.11\n",
            "APY (Total)  : 0.045\n",
            "------------------------------------------------------------\n",
            "\n",
            "Vault        : Rocket Pool rETH\n",
            "Protocol     : Rocket pool (collateral vault)\n",
            "Asset        : ETH\n",
            "Network      : mainnet\n",
            "Pool Address : 0xae78736Cd615f374D3085123A210448E74Fc6393\n",
            "Balance      : 6,027.4526 ETH\n",
            "Value (USD)  : $25,407,908.83\n",
            "APY (Total)  : 0.0259\n",
            "------------------------------------------------------------\n",
            "\n",
            "Vault        : Lido stETH\n",
            "Protocol     : Lido (collateral vault)\n",
            "Asset        : ETH\n",
            "Network      : mainnet\n",
            "Pool Address : 0xae7ab96520DE3A18E5e111B5EaAb095312D7fE84\n",
            "Balance      : 4,383.0982 ETH\n",
            "Value (USD)  : $16,184,590.00\n",
            "APY (Total)  : 0.0281\n",
            "------------------------------------------------------------\n",
            "\n",
            "Vault        : Stader ETHx\n",
            "Protocol     : Ethx (collateral vault)\n",
            "Asset        : ETH\n",
            "Network      : mainnet\n",
            "Pool Address : 0xA35b1B31Ce002FBF2058D22F30f95D405200A15b\n",
            "Balance      : 7,851.6771 ETH\n",
            "Value (USD)  : $30,894,897.51\n",
            "APY (Total)  : 0.0277\n",
            "------------------------------------------------------------\n",
            "\n",
            "Vault        : Aave v3 USDC\n",
            "Protocol     : Aave (collateral vault)\n",
            "Asset        : USDC\n",
            "Network      : mainnet\n",
            "Pool Address : 0x98C23E9d8f34FEFb1B7BD6a91B7FF122F4e16F5c\n",
            "Balance      : 36,222.7051 USDC\n",
            "Value (USD)  : $36,218.36\n",
            "APY (Total)  : 0.0381\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "data_tmp = []\n",
        "\n",
        "for p in positions.get('data', []):\n",
        "    # Basic metadata\n",
        "    pool_address = p.get('address', 'N/A')\n",
        "    protocol = p.get('protocol', {})\n",
        "    asset = p.get('asset', {})\n",
        "    lp_token = p.get('lpToken',{})\n",
        "    network = p.get('network', {})\n",
        "\n",
        "    # Display values\n",
        "    protocol_name = protocol.get('name', 'N/A').capitalize()\n",
        "    vault_name = p.get('name', p.get('vaultName', 'N/A'))\n",
        "    asset_symbol = asset.get('symbol', 'N/A')\n",
        "    network_name = network.get('name', 'N/A')\n",
        "    lp_symbol = lp_token.get('symbol', 'N/A')\n",
        "\n",
        "    # Numeric values\n",
        "    decimals = asset.get('decimals', 18)\n",
        "    raw_native = lp_token.get('balanceNative', '0')\n",
        "    raw_usd = lp_token.get('balanceUsd', '0')\n",
        "\n",
        "    try:\n",
        "        balance_native = int(raw_native) / (10 ** decimals)\n",
        "    except (ValueError, TypeError):\n",
        "        balance_native = 0.0\n",
        "\n",
        "    try:\n",
        "        balance_usd = float(raw_usd)\n",
        "    except (ValueError, TypeError):\n",
        "        balance_usd = 0.0\n",
        "\n",
        "    # APY\n",
        "    apy_total = p.get('apy', {}).get('total')\n",
        "    apy_base = p.get('apy', {}).get('base')\n",
        "    apy_reward = p.get('apy', {}).get('reward')\n",
        "\n",
        "    # save in dictionary for processing later\n",
        "    position_data_tmp = {\n",
        "        'network': network_name,\n",
        "        'asset_symbol': asset_symbol,\n",
        "        'protocol_name': protocol_name,\n",
        "        'vault_name': vault_name,\n",
        "        'balance_native': balance_native,\n",
        "        'balance_usd': balance_usd,\n",
        "        'apy_base': apy_base,\n",
        "        'apy_reward': apy_reward,\n",
        "        'apy_total': apy_total,\n",
        "    }\n",
        "\n",
        "    # Display\n",
        "    print(f\"\\nVault        : {vault_name}\")\n",
        "    print(f\"Protocol     : {protocol_name} ({protocol_product})\")\n",
        "    print(f\"Asset        : {asset_symbol}\")\n",
        "    print(f\"Network      : {network_name}\")\n",
        "    print(f\"Pool Address : {pool_address}\")\n",
        "    print(f\"Balance      : {balance_native:,.4f} {asset_symbol}\")\n",
        "    print(f\"Value (USD)  : ${balance_usd:,.2f}\")\n",
        "    print(f\"APY (Total)  : {apy_total}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    data_tmp.append(position_data_tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h51HRE41DXMd"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "One time use for benchmark calculation (being replaced above)\n",
        "\"\"\"\n",
        "\n",
        "# user config - please don't stress the execution button as we might be left without credit\n",
        "client = VaultsSdk(api_key=ENSConfig.VAULTS_FYI_API_KEY)\n",
        "\n",
        "# ====================================================================================\n",
        "# VAULTS CONFIGURATION\n",
        "# ====================================================================================\n",
        "\n",
        "vaults = [\n",
        "    {\n",
        "        'label': 'Aave v3 USDC',\n",
        "        'address': '0x98C23E9d8f34FEFb1B7BD6a91B7FF122F4e16F5c',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'USDC',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "    {\n",
        "        'label': 'Compound v3 USDC',\n",
        "        'address': '0xc3d688B66703497DAA19211EEdff47f25384cdc3',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'USDC',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "    {\n",
        "        'label': 'Aave v3 DAI',\n",
        "        'address': '0x018008bfb33d285247A21d44E50697654f754e63',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'DAI',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "    {\n",
        "        'label': 'Savings DAI (sDAI)',\n",
        "        'address': '0x83F20F44975D03b1b09e64809B757c47f942BEeA',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'DAI',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "    {\n",
        "        'label': 'Savings USDS',\n",
        "        'address': '0xa3931d71877C0E7a3148CB7Eb4463524FEc27fbD',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'USDS',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "]\n",
        "\n",
        "# ====================================================================================\n",
        "# GET HISTORICAL DATA\n",
        "# ====================================================================================\n",
        "\n",
        "historical_data = []\n",
        "\n",
        "for vault in vaults:\n",
        "    vault_historical_data_tmp = client.get_vault_historical_data(\n",
        "        network = vault['network'],\n",
        "        vault_address = vault['address'],\n",
        "        page = 0,\n",
        "        perPage = 1000,\n",
        "        apyInterval = '1day',\n",
        "        granularity = '1day'\n",
        "        # fromTimestamp: 1640995200,\n",
        "        # toTimestamp: 1672531200\n",
        "    )\n",
        "\n",
        "    for record in vault_historical_data_tmp['data']:\n",
        "        vault_historical_data = {\n",
        "            'label': vault['label'],\n",
        "            'asset': vault['asset'],\n",
        "            'allocation': vault['allocation'],\n",
        "            'timestamp': record['timestamp'],\n",
        "            'apy_base': record['apy']['base'],\n",
        "            'apy_reward': record['apy']['reward'],\n",
        "            'apy_total': record['apy']['total']\n",
        "        }\n",
        "\n",
        "        historical_data.append(vault_historical_data)\n",
        "\n",
        "df = pd.DataFrame.from_records(historical_data)\n",
        "\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], unit = 's')\n",
        "\n",
        "df['month'] = df['timestamp'].dt.to_period('M').dt.to_timestamp()\n",
        "df_monthly = df.drop('timestamp', axis = 1).groupby(\n",
        "    ['month', 'allocation', 'asset', 'label'],\n",
        "    as_index=False\n",
        ").mean()\n",
        "\n",
        "df_monthly.to_csv('monthly_yields.csv')\n",
        "\n",
        "df['year'] = df['timestamp'].dt.to_period('Y').dt.to_timestamp()\n",
        "df_yearly = df.drop('timestamp', axis = 1).groupby(\n",
        "    ['year', 'allocation', 'asset', 'label'],\n",
        "    as_index=False\n",
        ").mean()\n",
        "\n",
        "df_yearly.to_csv('yearly_yields.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ_sCo3p7ZZw"
      },
      "source": [
        "# other utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyGzMs4QGPZj"
      },
      "source": [
        "## cow swap order exec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3FprOT-GPEE",
        "outputId": "68ac55a7-fdbb-4ba9-a9e8-3aa8ccafce28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+--------------------------------------------+--------------------------------------------+---------------+------------------+------------------+------------------+-----------------+\n",
            "|    | sell_token                                 | buy_token                                  |   sell_amount |       buy_amount |   buy_sell_price |   sell_buy_price |   market_impact |\n",
            "|----+--------------------------------------------+--------------------------------------------+---------------+------------------+------------------+------------------+-----------------|\n",
            "|  0 | 0xae78736cd615f374d3085123a210448e74fc6393 | 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48 |      0.999707 |   4167.84        |          4169.06 |      0.000239862 |        1        |\n",
            "|  1 | 0xae78736cd615f374d3085123a210448e74fc6393 | 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48 |      9.99976  |  41679.4         |          4168.04 |      0.000239921 |        0.999754 |\n",
            "|  2 | 0xae78736cd615f374d3085123a210448e74fc6393 | 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48 |     99.9984   | 416555           |          4165.62 |      0.00024006  |        0.999173 |\n",
            "|  3 | 0xae78736cd615f374d3085123a210448e74fc6393 | 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48 |    199.999    | 832434           |          4162.19 |      0.000240258 |        0.998352 |\n",
            "|  4 | 0xae78736cd615f374d3085123a210448e74fc6393 | 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48 |    299.999    |      1.24878e+06 |          4162.63 |      0.000240233 |        0.998456 |\n",
            "|  5 | 0xae78736cd615f374d3085123a210448e74fc6393 | 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48 |    399.999    |      1.66327e+06 |          4158.19 |      0.000240489 |        0.997391 |\n",
            "|  6 | 0xae78736cd615f374d3085123a210448e74fc6393 | 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48 |    499.998    |      2.08073e+06 |          4161.48 |      0.000240299 |        0.99818  |\n",
            "|  7 | 0xae78736cd615f374d3085123a210448e74fc6393 | 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48 |    999.998    |      4.13243e+06 |          4132.44 |      0.000241988 |        0.991214 |\n",
            "+----+--------------------------------------------+--------------------------------------------+---------------+------------------+------------------+------------------+-----------------+\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Get quote for different order sizes for selling different assets in Cow Swap.\n",
        "\n",
        "\n",
        "Make more robust:\n",
        "- select tokens by symbol or smth similar & get decimals + if reward-bearing or not\n",
        "- if token is reward-bearing get the amount of underlying tokens (get ABI + rpc call to get the amount of underlying tokens)\n",
        "- then get the quote for the underlying tokens\n",
        "\"\"\"\n",
        "\n",
        "# params\n",
        "cow_api_url = 'https://api.cow.fi/mainnet/api/v1/quote'\n",
        "endowment_address = '0x4f2083f5fbede34c2714affb3105539775f7fe64'\n",
        "\n",
        "# token addresses\n",
        "reth_address = '0xae78736cd615f374d3085123a210448e74fc6393'\n",
        "weth_address = '0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2'\n",
        "usdc_address = '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48'\n",
        "\n",
        "# Order parameters\n",
        "sell_token_decimals = 18\n",
        "buy_token_decimals = 6\n",
        "clip_sizes = [1, 10, 100, 200, 300, 400, 500, 1000]\n",
        "\n",
        "data_tmp = []\n",
        "\n",
        "# data request\n",
        "for clip_size in clip_sizes:\n",
        "    r = requests.post(\n",
        "        cow_api_url,\n",
        "        json={\n",
        "            \"sellToken\": reth_address,\n",
        "            \"buyToken\": usdc_address,\n",
        "            \"receiver\": endowment_address,\n",
        "            \"from\": endowment_address,\n",
        "            \"onchainOrder\": False,\n",
        "            \"kind\": \"sell\",\n",
        "            \"sellAmountBeforeFee\": str(clip_size * (10 ** sell_token_decimals))\n",
        "        }\n",
        "    )\n",
        "\n",
        "    response_data = r.json()['quote']\n",
        "\n",
        "    data_tmp.append({\n",
        "        'sell_token': response_data['sellToken'],\n",
        "        'buy_token': response_data['buyToken'],\n",
        "        'sell_amount': float(response_data['sellAmount']) / (10 ** sell_token_decimals),\n",
        "        'buy_amount': float(response_data['buyAmount']) / (10 ** buy_token_decimals),\n",
        "    })\n",
        "    time.sleep(2)\n",
        "\n",
        "df = pd.DataFrame.from_records(data_tmp)\n",
        "\n",
        "df['buy_sell_price'] = df['buy_amount']/df['sell_amount']\n",
        "df['sell_buy_price'] = df['sell_amount']/df['buy_amount']\n",
        "df['market_impact'] = df['buy_sell_price'] / df['buy_sell_price'].iloc[0]\n",
        "\n",
        "print(tabulate(df, headers='keys', tablefmt='psql'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [st] rb underlying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "getEthValue(1 rETH) = 1.139398385648086039 ETH at block 22766544\n"
          ]
        }
      ],
      "source": [
        "from web3 import Web3\n",
        "import json\n",
        "\n",
        "# infura api key\n",
        "api_key = \"06c32bc518be488f85e27eced5883244\"\n",
        "\n",
        "# Connect to Ethereum mainnet\n",
        "w3 = Web3(Web3.HTTPProvider(f\"https://mainnet.infura.io/v3/{api_key}\"))\n",
        "assert w3.is_connected(), \"Failed to connect to Ethereum node\"\n",
        "\n",
        "# Contract setup\n",
        "contract_address = Web3.to_checksum_address(\"0xae78736cd615f374d3085123a210448e74fc6393\")\n",
        "abi = json.loads(\"\"\"\n",
        "[{\n",
        "  \"constant\": true,\n",
        "  \"inputs\": [{\"internalType\": \"uint256\",\"name\": \"_rethAmount\",\"type\": \"uint256\"}],\n",
        "  \"name\": \"getEthValue\",\n",
        "  \"outputs\": [{\"internalType\": \"uint256\",\"name\": \"\",\"type\": \"uint256\"}],\n",
        "  \"payable\": false,\n",
        "  \"stateMutability\": \"view\",\n",
        "  \"type\": \"function\"\n",
        "}]\n",
        "\"\"\")\n",
        "contract = w3.eth.contract(address=contract_address, abi=abi)\n",
        "\n",
        "# Call getEthValue at block 22766544\n",
        "reth_amount = w3.to_wei(1, 'ether')\n",
        "block_number = 22766544\n",
        "eth_value_wei = contract.functions.getEthValue(reth_amount).call(block_identifier=block_number)\n",
        "eth_value = w3.from_wei(eth_value_wei, 'ether')\n",
        "\n",
        "print(f\"getEthValue(1 rETH) = {eth_value} ETH at block {block_number}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "kpk-general",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
