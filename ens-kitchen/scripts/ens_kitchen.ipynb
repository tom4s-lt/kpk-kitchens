{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyKCCb9cT-mF"
      },
      "source": [
        "# ens_kitchen notebook\n",
        "\n",
        "Jupyter notebook for data extraction and processing for ENS Endowment data update & analysis. **Execution is on Colab** (not locally).\n",
        "\n",
        "Sections:\n",
        "1. **setup:** done in the first section in order to have proper config for the whole nobtebook.\n",
        "2. **data collection:** section used for collecting data for the jt kitchen.\n",
        "    1. **prices:** fetch prices for ENS portfolio relevant tokens.\n",
        "    2. **sf ens financials:** fetch all ens financial transactions.\n",
        "    3. **ens dao holdings:** collect ens dao holdings along all DAO wallets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNceggc7DPaQ"
      },
      "source": [
        "# setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LigVHewUQpM",
        "outputId": "b4ca3f0b-ed7e-475c-8f56-bd54f46d4933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/bin/pip\", line 11, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 236, in _main\n",
            "    self.handle_pip_version_check(options)\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/pip/_internal/cli/req_command.py\", line 188, in handle_pip_version_check\n",
            "    pip_self_version_check(session, options)\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/pip/_internal/self_outdated_check.py\", line 231, in pip_self_version_check\n",
            "    installed_dist = get_default_environment().get_distribution(\"pip\")\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py\", line 189, in get_distribution\n",
            "    return next(matches, None)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py\", line 184, in <genexpr>\n",
            "    matches = (\n",
            "              ^\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/pip/_internal/metadata/base.py\", line 626, in iter_all_distributions\n",
            "    for dist in self._iter_distributions():\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py\", line 176, in _iter_distributions\n",
            "    yield from finder.find(location)\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py\", line 79, in find\n",
            "    for dist, info_location in self._find_impl(location):\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py\", line 64, in _find_impl\n",
            "    raw_name = get_dist_name(dist)\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_compat.py\", line 52, in get_dist_name\n",
            "    name = cast(Any, dist).name\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/importlib/metadata/__init__.py\", line 457, in name\n",
            "    return self.metadata['Name']\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/importlib/metadata/__init__.py\", line 452, in metadata\n",
            "    return _adapters.Message(email.message_from_string(text))\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/email/__init__.py\", line 37, in message_from_string\n",
            "    return Parser(*args, **kws).parsestr(s)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/email/parser.py\", line 64, in parsestr\n",
            "    return self.parse(StringIO(text), headersonly=headersonly)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/email/parser.py\", line 53, in parse\n",
            "    feedparser.feed(data)\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/email/feedparser.py\", line 174, in feed\n",
            "    self._call_parse()\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/email/feedparser.py\", line 178, in _call_parse\n",
            "    self._parse()\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/email/feedparser.py\", line 238, in _parsegen\n",
            "    self._parse_headers(headers)\n",
            "  File \"/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/email/feedparser.py\", line 489, in _parse_headers\n",
            "    if line.startswith('From '):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'spice_query_id' from 'kpk_kitchens.utils' (/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/kpk_kitchens/utils.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 26\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# ==============================================\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Import Required Libraries\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# ==============================================\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# user-built config class and functions\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkpk_kitchens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ENSConfig\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkpk_kitchens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m etl_gen_df_from_gsheet, gecko_get_price_historical, spice_query_id\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Other libraries\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'spice_query_id' from 'kpk_kitchens.utils' (/Users/tomas/anaconda3/envs/kpk-general/lib/python3.12/site-packages/kpk_kitchens/utils.py)"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Setup all the required variables & logic for the notebook.\n",
        "\"\"\"\n",
        "\n",
        "# ==============================================\n",
        "# Install required packages\n",
        "# ==============================================\n",
        "\n",
        "# kpk_kitchens - user-built package to run in the colab\n",
        "GITHUB_TOKEN = \"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\"\n",
        "BRANCH = \"main\"\n",
        "! pip install git+https://{GITHUB_TOKEN}@github.com/tom4s-lt/kpk-kitchens.git@{BRANCH}\n",
        "\n",
        "# ==============================================\n",
        "# Import Required Libraries\n",
        "# ==============================================\n",
        "\n",
        "# user-built config class and functions\n",
        "from kpk_kitchens.config import ENSConfig\n",
        "from kpk_kitchens.utils import etl_gen_df_from_gsheet, gecko_get_price_historical, spice_query_id\n",
        "\n",
        "# Google authentication libraries\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "# Other libraries\n",
        "from vaultsfyi import VaultsSdk\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# ==============================================\n",
        "#  Initialize script variables & params\n",
        "# ==============================================\n",
        "\n",
        "# google authentication, credentials & client\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Create the data directory\n",
        "os.makedirs(ENSConfig.DATA_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUrdRig4DPaR"
      },
      "source": [
        "# data collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7az2fYFDPaR"
      },
      "source": [
        "## prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8r2e7CIDPaS"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fetches prices for ens portfolio relevant tokens from CoinGecko.\n",
        "\n",
        "args:\n",
        "    none\n",
        "\n",
        "returns:\n",
        "    prices.csv: prices for all assets in the portfolio\n",
        "\"\"\"\n",
        "\n",
        "# Fetch assets from Google Sheet\n",
        "json_lk_assets = etl_gen_df_from_gsheet(gc, ENSConfig.WORKBOOK_URL, ENSConfig.LK_ASSETS_TAB)\n",
        "\n",
        "# filter - only ENS assets\n",
        "json_ens_assets = [\n",
        "    asset for asset in json_lk_assets\n",
        "    if asset.get(\"company\") == \"ENS\"\n",
        "]\n",
        "\n",
        "# Separate stablecoins and non-stablecoins - only symbol_level_0\n",
        "stablecoins = [\n",
        "    asset for asset in json_ens_assets\n",
        "    if (asset.get(\"type_market\") == \"stablecoin\") and (asset.get(\"type_level\") == 0)\n",
        "]\n",
        "\n",
        "non_stablecoins = [\n",
        "    asset for asset in json_ens_assets\n",
        "    if (asset.get(\"type_market\") != \"stablecoin\") and (asset.get(\"type_level\") == 0)\n",
        "]\n",
        "\n",
        "print(f\"Found {len(stablecoins)} stablecoins and {len(non_stablecoins)} non-stablecoins\")\n",
        "\n",
        "print(\"\\nOnly level_0/underlying is fetched because that's waht's prices in the reporting\")\n",
        "\n",
        "# Filter duplicates on symbol_level_0 for non_stablecoins\n",
        "non_stablecoins = list({\n",
        "    asset.get(\"symbol_level_0\", \"\"): asset\n",
        "    for asset in non_stablecoins\n",
        "    if asset.get(\"symbol_level_0\", \"\")\n",
        "}.values())\n",
        "\n",
        "# Fetch and process price data for non-stablecoin assets\n",
        "price_data = []\n",
        "for asset in non_stablecoins:\n",
        "    print(f\"Fetching data for {asset['symbol']}...\")\n",
        "\n",
        "    gecko_hist_data = gecko_get_price_historical(\n",
        "        base_url=ENSConfig.COINGECKO_API_BASE_URL,\n",
        "        asset_id=asset['id_gecko'],\n",
        "        api_key=ENSConfig.COINGECKO_API_KEY,\n",
        "        max_retries=ENSConfig.MAX_RETRIES,\n",
        "        retry_delay=ENSConfig.RETRY_DELAY,\n",
        "        timeout=ENSConfig.DEFAULT_TIMEOUT,\n",
        "        # params is function default - 365 days max with free key\n",
        "        headers={\n",
        "            'accept': 'application/json',\n",
        "            'x-cg-demo-api-key': ENSConfig.COINGECKO_API_KEY\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if gecko_hist_data:\n",
        "        # Create DataFrame for current asset\n",
        "        df = pd.DataFrame(gecko_hist_data['prices'], columns=['ts', 'price'])\n",
        "        df['id_gecko'] = asset['id_gecko']\n",
        "        df['symbol'] = asset['symbol']\n",
        "        price_data.append(df)\n",
        "        print(f\"Successfully fetched data for {asset['symbol']}\")\n",
        "\n",
        "    time.sleep(3)  # Rate limiting\n",
        "\n",
        "print(\"\\nPrice data collection complete\")\n",
        "\n",
        "# Process price data\n",
        "print(\"\\nProcessing price data...\")\n",
        "df_prices = pd.concat(price_data)\n",
        "df_prices['date'] = pd.to_datetime(df_prices['ts'], unit='ms')\n",
        "\n",
        "# Resample to daily frequency and calculate mean prices\n",
        "df_prices = (df_prices\n",
        "    .groupby(['symbol', 'id_gecko'])\n",
        "    .resample('D', on='date')\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    [['date', 'symbol', 'id_gecko', 'price']]  # Drop ts\n",
        "    .sort_values('date', ascending=False)\n",
        ")\n",
        "\n",
        "print(\"\\nPrice data processing complete\")\n",
        "\n",
        "# Add stablecoin data with price=1\n",
        "if stablecoins:\n",
        "    print(\"\\nAdding stablecoin data...\")\n",
        "    # Get unique dates from the price data\n",
        "    dates = df_prices['date'].unique()\n",
        "\n",
        "    # Create stablecoin records\n",
        "    stablecoin_data = []\n",
        "    for asset in stablecoins:\n",
        "        for date in dates:\n",
        "            stablecoin_data.append({\n",
        "                'date': date,\n",
        "                'symbol': asset['symbol'],\n",
        "                'id_gecko': asset['id_gecko'],\n",
        "                'price': 1.0\n",
        "            })\n",
        "\n",
        "    # Convert to DataFrame and append to price data\n",
        "    df_stablecoins = pd.DataFrame(stablecoin_data)\n",
        "    df_prices = pd.concat([df_prices, df_stablecoins], ignore_index=True)\n",
        "    df_prices = df_prices.sort_values('date', ascending=False)\n",
        "\n",
        "print(\"\\nStablecoin prices complete\")\n",
        "\n",
        "# Export results\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.PRICES_CSV}...\")\n",
        "df_prices.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.PRICES_CSV}\", index=False)\n",
        "print(\"\\nExport complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agrXUgEnDPaS"
      },
      "source": [
        "## sf ens financials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHK1TZl7DPaT"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fetches ENS financial data from extractor query <- SF dune queries\n",
        "Might add more metadata to create different aggregations but not necessary for now.\n",
        "    - wallel labels that come from lk_addresses in the kitchen\n",
        "\n",
        "args:\n",
        "    token_address: ENS token address - comment in the query to exclude/include by excluding parameters\n",
        "\n",
        "returns:\n",
        "    financials.csv: historical financial data for ENS\n",
        "\"\"\"\n",
        "\n",
        "# create params for query\n",
        "parameters = {\n",
        "    'token_address': ENSConfig.ENS_TOKEN_ADDRESS\n",
        "}\n",
        "\n",
        "# Get data from dune query\n",
        "df_financials = spice_query_id(\n",
        "    query_id=ENSConfig.DUNE_QID_EXTRACT_SF_ENS_FINANCIALS_PER_WALLET,\n",
        "    api_key=ENSConfig.DUNE_API_KEY,\n",
        "    parameters=parameters,\n",
        "    refresh=True,\n",
        ")\n",
        "\n",
        "print(\"Financial data obtained from Dune.\")\n",
        "\n",
        "# period/year data comes with hh:mm:ss:... - convert to date/year only\n",
        "df_financials['year'] = pd.to_datetime(df_financials['year'])\n",
        "df_financials['year'] = df_financials['year'].dt.year\n",
        "\n",
        "df_financials['period'] = pd.to_datetime(df_financials['period'])\n",
        "df_financials['period'] = df_financials['period'].dt.date\n",
        "\n",
        "# Export results\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.FINANCIALS_CSV}...\")\n",
        "df_financials.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.FINANCIALS_CSV}\", index=False)\n",
        "print(\"\\nExport complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DPE2r4zDPaT"
      },
      "source": [
        "## ens dao holdings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPvfkhEUDPaU"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fetches ENS DAO (excl. Endowment) holdings extractor query <- SF dune queries\n",
        "\n",
        "args:\n",
        "    query params: addresses coming from lk_Addresses, custom_date\n",
        "\n",
        "returns:\n",
        "    financials.csv: historical financial data for ENS\n",
        "\"\"\"\n",
        "\n",
        "# Fetch addresses from Google Sheet\n",
        "json_lk_addresses = etl_gen_df_from_gsheet(gc, ENSConfig.WORKBOOK_URL, ENSConfig.LK_ADDRESSES_TAB)\n",
        "\n",
        "# get only the addresses - remember to lower for correct matching later\n",
        "ens_addresses = [\n",
        "    address.get('address').lower() for address in json_lk_addresses\n",
        "]\n",
        "\n",
        "ens_addresses = \",\".join(ens_addresses)\n",
        "\n",
        "# create params for query\n",
        "custom_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
        "parameters = {\n",
        "    'ens_addresses': ens_addresses,\n",
        "    'custom_date': custom_date\n",
        "}\n",
        "\n",
        "# Get data from dune query\n",
        "df_holdings = spice_query_id(\n",
        "    query_id=ENSConfig.DUNE_QID_EXTRACT_ENS_DAO_HOLDINGS,\n",
        "    api_key=ENSConfig.DUNE_API_KEY,\n",
        "    parameters=parameters,\n",
        "    refresh=True,\n",
        ")\n",
        "\n",
        "print(\"Holdings data obtained from Dune.\")\n",
        "\n",
        "# period data comes with hh:mm:ss:... - convert to date only\n",
        "df_holdings['day'] = pd.to_datetime(df_holdings['day'])\n",
        "df_holdings['day'] = df_holdings['day'].dt.date\n",
        "\n",
        "# Export results\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.HOLDINGS_CSV}...\")\n",
        "df_holdings.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.HOLDINGS_CSV}\", index=False)\n",
        "print(\"\\nExport complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbCj9Xj_DQT3"
      },
      "source": [
        "## [standalone] vaults.fyi allocation monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# user config - please don't stress the execution button as we might be left without credit\n",
        "client = VaultsSdk(api_key=ENSConfig.VAULTS_FYI_API_KEY)\n",
        "\n",
        "# wallet address\n",
        "wallet_address = ENSConfig.ENS_ENDOWMENT_ADDRESS\n",
        "\n",
        "# network to search\n",
        "networks = ['mainnet']\n",
        "\n",
        "# Fetch existing portfolio positions\n",
        "positions = client.get_positions(\n",
        "    user_address=wallet_address,\n",
        "    allowedNetworks=networks\n",
        ")\n",
        "\n",
        "print(\"\\n========== CURRENT PORTFOLIO POSITIONS ==========\")\n",
        "\n",
        "for p in positions.get('data', []):\n",
        "    # Basic metadata\n",
        "    pool_address = p.get('address', 'N/A')\n",
        "    protocol = p.get('protocol', {})\n",
        "    asset = p.get('asset', {})\n",
        "    lp_token = p.get('lpToken',{})\n",
        "    network = p.get('network', {})\n",
        "    lp_token = p.get('lpToken', {})\n",
        "\n",
        "    # Extract values safely\n",
        "    protocol_name = protocol.get('name', 'N/A').capitalize()\n",
        "    protocol_product = protocol.get('product', '')\n",
        "    vault_name = p.get('name', p.get('vaultName', 'N/A'))\n",
        "    asset_symbol = asset.get('symbol', 'N/A')\n",
        "    network_name = network.get('name', 'N/A')\n",
        "    lp_symbol = lp_token.get('symbol', 'N/A')\n",
        "\n",
        "    # Numeric values\n",
        "    decimals = asset.get('decimals', 18)\n",
        "    raw_native = lp_token.get('balanceNative', '0')\n",
        "    raw_usd = lp_token.get('balanceUsd', '0')\n",
        "\n",
        "    try:\n",
        "        balance_native = int(raw_native) / (10 ** decimals)\n",
        "    except (ValueError, TypeError):\n",
        "        balance_native = 0.0\n",
        "\n",
        "    try:\n",
        "        balance_usd = float(raw_usd)\n",
        "    except (ValueError, TypeError):\n",
        "        balance_usd = 0.0\n",
        "\n",
        "    # APY\n",
        "    apy_total = p.get('apy', {}).get('total')\n",
        "    apy_display = f\"{apy_total:.2%}\" if isinstance(apy_total, (int, float)) else \"N/A\"\n",
        "\n",
        "    # Display\n",
        "    print(f\"\\nVault        : {vault_name}\")\n",
        "    print(f\"Protocol     : {protocol_name} ({protocol_product})\")\n",
        "    print(f\"Asset        : {asset_symbol}\")\n",
        "    print(f\"Network      : {network_name}\")\n",
        "    print(f\"Pool Address : {pool_address}\")\n",
        "    print(f\"Balance      : {balance_native:,.4f} {asset_symbol}\")\n",
        "    print(f\"Value (USD)  : ${balance_usd:,.2f}\")\n",
        "    print(f\"APY (Total)  : {apy_display}\")\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h51HRE41DXMd"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "One time use for benchmark calculation (being replaced above)\n",
        "\"\"\"\n",
        "\n",
        "# user config - please don't stress the execution button as we might be left without credit\n",
        "client = VaultsSdk(api_key=ENSConfig.VAULTS_FYI_API_KEY)\n",
        "\n",
        "# ====================================================================================\n",
        "# VAULTS CONFIGURATION\n",
        "# ====================================================================================\n",
        "\n",
        "vaults = [\n",
        "    {\n",
        "        'label': 'Aave v3 USDC',\n",
        "        'address': '0x98C23E9d8f34FEFb1B7BD6a91B7FF122F4e16F5c',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'USDC',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "    {\n",
        "        'label': 'Compound v3 USDC',\n",
        "        'address': '0xc3d688B66703497DAA19211EEdff47f25384cdc3',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'USDC',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "    {\n",
        "        'label': 'Aave v3 DAI',\n",
        "        'address': '0x018008bfb33d285247A21d44E50697654f754e63',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'DAI',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "    {\n",
        "        'label': 'Savings DAI (sDAI)',\n",
        "        'address': '0x83F20F44975D03b1b09e64809B757c47f942BEeA',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'DAI',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "    {\n",
        "        'label': 'Savings USDS',\n",
        "        'address': '0xa3931d71877C0E7a3148CB7Eb4463524FEc27fbD',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'USDS',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "]\n",
        "\n",
        "# ====================================================================================\n",
        "# GET HISTORICAL DATA\n",
        "# ====================================================================================\n",
        "\n",
        "historical_data = []\n",
        "\n",
        "for vault in vaults:\n",
        "    vault_historical_data_tmp = client.get_vault_historical_data(\n",
        "        network = vault['network'],\n",
        "        vault_address = vault['address'],\n",
        "        page = 0,\n",
        "        perPage = 1000,\n",
        "        apyInterval = '1day',\n",
        "        granularity = '1day'\n",
        "        # fromTimestamp: 1640995200,\n",
        "        # toTimestamp: 1672531200\n",
        "    )\n",
        "\n",
        "    for record in vault_historical_data_tmp['data']:\n",
        "        vault_historical_data = {\n",
        "            'label': vault['label'],\n",
        "            'asset': vault['asset'],\n",
        "            'allocation': vault['allocation'],\n",
        "            'timestamp': record['timestamp'],\n",
        "            'apy_base': record['apy']['base'],\n",
        "            'apy_reward': record['apy']['reward'],\n",
        "            'apy_total': record['apy']['total']\n",
        "        }\n",
        "\n",
        "        historical_data.append(vault_historical_data)\n",
        "\n",
        "df = pd.DataFrame.from_records(historical_data)\n",
        "\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], unit = 's')\n",
        "\n",
        "df['month'] = df['timestamp'].dt.to_period('M').dt.to_timestamp()\n",
        "df_monthly = df.drop('timestamp', axis = 1).groupby(\n",
        "    ['month', 'allocation', 'asset', 'label'],\n",
        "    as_index=False\n",
        ").mean()\n",
        "\n",
        "df_monthly.to_csv('monthly_yields.csv')\n",
        "\n",
        "df['year'] = df['timestamp'].dt.to_period('Y').dt.to_timestamp()\n",
        "df_yearly = df.drop('timestamp', axis = 1).groupby(\n",
        "    ['year', 'allocation', 'asset', 'label'],\n",
        "    as_index=False\n",
        ").mean()\n",
        "\n",
        "df_yearly.to_csv('yearly_yields.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "kpk-general",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
