{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyKCCb9cT-mF"
      },
      "source": [
        "# ens_kitchen notebook\n",
        "\n",
        "Jupyter notebook for data extraction and processing for ENS Endowment data update & analysis. **Execution is on Colab** (not locally).\n",
        "\n",
        "Sections:\n",
        "1. **setup:** done in the first section in order to have proper config for the whole nobtebook.\n",
        "2. **data collection:** section used for collecting data for the jt kitchen.\n",
        "    1. **prices:** fetch prices for ENS portfolio relevant tokens.\n",
        "    2. **sf ens financials:** fetch all ens financial transactions.\n",
        "    3. **ens dao holdings:** collect ens dao holdings along all DAO wallets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNceggc7DPaQ"
      },
      "source": [
        "# setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LigVHewUQpM",
        "outputId": "b4ca3f0b-ed7e-475c-8f56-bd54f46d4933"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSetup all the required variables & logic for the notebook.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# ==============================================\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#  Install Google Auth Libraries + auth itself (go first to click on pop up quickly)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# ==============================================\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Google authentication libraries\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auth\n\u001b[1;32m     11\u001b[0m auth\u001b[38;5;241m.\u001b[39mauthenticate_user()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgspread\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Setup all the required variables & logic for the notebook.\n",
        "\"\"\"\n",
        "\n",
        "# ==============================================\n",
        "#  Install Google Auth Libraries + auth itself (go first to click on pop up quickly)\n",
        "# ==============================================\n",
        "\n",
        "# Google authentication libraries\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "# ==============================================\n",
        "#  Install Required Packages\n",
        "# ==============================================\n",
        "\n",
        "# user-built packages to run in the colab\n",
        "GITHUB_TOKEN = \"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\"\n",
        "BRANCH = \"main\"\n",
        "! pip install git+https://{GITHUB_TOKEN}@github.com/tom4s-lt/kpk-kitchens.git@{BRANCH}\n",
        "\n",
        "# ==============================================\n",
        "#  Import Required Libraries\n",
        "# ==============================================\n",
        "\n",
        "# user-built config class and functions\n",
        "from kpk_kitchens.config import ENSConfig\n",
        "from kpk_kitchens.utils import etl_gen_df_from_gsheet, gecko_get_price_historical, spice_query_id\n",
        "\n",
        "# Other libraries\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "from typing import Optional, Dict, Any, List\n",
        "\n",
        "# ==============================================\n",
        "#  Initialize script variables & params\n",
        "# ==============================================\n",
        "\n",
        "# google credentials & client\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Create the data directory\n",
        "os.makedirs(ENSConfig.DATA_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUrdRig4DPaR"
      },
      "source": [
        "# data collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7az2fYFDPaR"
      },
      "source": [
        "## prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8r2e7CIDPaS"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fetches prices for ens portfolio relevant tokens from CoinGecko.\n",
        "\n",
        "args:\n",
        "    none\n",
        "\n",
        "returns:\n",
        "    prices.csv: prices for all assets in the portfolio\n",
        "\"\"\"\n",
        "\n",
        "# Fetch assets from Google Sheet\n",
        "json_lk_assets = etl_gen_df_from_gsheet(gc, ENSConfig.WORKBOOK_URL, ENSConfig.LK_ASSETS_TAB)\n",
        "\n",
        "# filter - only ENS assets\n",
        "json_ens_assets = [\n",
        "    asset for asset in json_lk_assets\n",
        "    if asset.get(\"company\") == \"ENS\"\n",
        "]\n",
        "\n",
        "# Separate stablecoins and non-stablecoins - only symbol_level_0\n",
        "stablecoins = [\n",
        "    asset for asset in json_ens_assets\n",
        "    if (asset.get(\"type_market\") == \"stablecoin\") and (asset.get(\"type_level\") == 0)\n",
        "]\n",
        "\n",
        "non_stablecoins = [\n",
        "    asset for asset in json_ens_assets\n",
        "    if (asset.get(\"type_market\") != \"stablecoin\") and (asset.get(\"type_level\") == 0)\n",
        "]\n",
        "\n",
        "print(f\"Found {len(stablecoins)} stablecoins and {len(non_stablecoins)} non-stablecoins\")\n",
        "\n",
        "print(\"\\nOnly level_0/underlying is fetched because that's waht's prices in the reporting\")\n",
        "\n",
        "# Filter duplicates on symbol_level_0 for non_stablecoins\n",
        "non_stablecoins = list({\n",
        "    asset.get(\"symbol_level_0\", \"\"): asset\n",
        "    for asset in non_stablecoins\n",
        "    if asset.get(\"symbol_level_0\", \"\")\n",
        "}.values())\n",
        "\n",
        "# Fetch and process price data for non-stablecoin assets\n",
        "price_data = []\n",
        "for asset in non_stablecoins:\n",
        "    print(f\"Fetching data for {asset['symbol']}...\")\n",
        "\n",
        "    gecko_hist_data = gecko_get_price_historical(\n",
        "        base_url=ENSConfig.COINGECKO_API_BASE_URL,\n",
        "        asset_id=asset['id_gecko'],\n",
        "        api_key=ENSConfig.COINGECKO_API_KEY,\n",
        "        max_retries=ENSConfig.MAX_RETRIES,\n",
        "        retry_delay=ENSConfig.RETRY_DELAY,\n",
        "        timeout=ENSConfig.DEFAULT_TIMEOUT,\n",
        "        # params is function default - 365 days max with free key\n",
        "        headers={\n",
        "            'accept': 'application/json',\n",
        "            'x-cg-demo-api-key': ENSConfig.COINGECKO_API_KEY\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if gecko_hist_data:\n",
        "        # Create DataFrame for current asset\n",
        "        df = pd.DataFrame(gecko_hist_data['prices'], columns=['ts', 'price'])\n",
        "        df['id_gecko'] = asset['id_gecko']\n",
        "        df['symbol'] = asset['symbol']\n",
        "        price_data.append(df)\n",
        "        print(f\"Successfully fetched data for {asset['symbol']}\")\n",
        "\n",
        "    time.sleep(3)  # Rate limiting\n",
        "\n",
        "print(\"\\nPrice data collection complete\")\n",
        "\n",
        "# Process price data\n",
        "print(\"\\nProcessing price data...\")\n",
        "df_prices = pd.concat(price_data)\n",
        "df_prices['date'] = pd.to_datetime(df_prices['ts'], unit='ms')\n",
        "\n",
        "# Resample to daily frequency and calculate mean prices\n",
        "df_prices = (df_prices\n",
        "    .groupby(['symbol', 'id_gecko'])\n",
        "    .resample('D', on='date')\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    [['date', 'symbol', 'id_gecko', 'price']]  # Drop ts\n",
        "    .sort_values('date', ascending=False)\n",
        ")\n",
        "\n",
        "print(\"\\nPrice data processing complete\")\n",
        "\n",
        "# Add stablecoin data with price=1\n",
        "if stablecoins:\n",
        "    print(\"\\nAdding stablecoin data...\")\n",
        "    # Get unique dates from the price data\n",
        "    dates = df_prices['date'].unique()\n",
        "\n",
        "    # Create stablecoin records\n",
        "    stablecoin_data = []\n",
        "    for asset in stablecoins:\n",
        "        for date in dates:\n",
        "            stablecoin_data.append({\n",
        "                'date': date,\n",
        "                'symbol': asset['symbol'],\n",
        "                'id_gecko': asset['id_gecko'],\n",
        "                'price': 1.0\n",
        "            })\n",
        "\n",
        "    # Convert to DataFrame and append to price data\n",
        "    df_stablecoins = pd.DataFrame(stablecoin_data)\n",
        "    df_prices = pd.concat([df_prices, df_stablecoins], ignore_index=True)\n",
        "    df_prices = df_prices.sort_values('date', ascending=False)\n",
        "\n",
        "print(\"\\nStablecoin prices complete\")\n",
        "\n",
        "# Export results\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.PRICES_CSV}...\")\n",
        "df_prices.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.PRICES_CSV}\", index=False)\n",
        "print(\"\\nExport complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agrXUgEnDPaS"
      },
      "source": [
        "## sf ens financials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHK1TZl7DPaT"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fetches ENS financial data from extractor query <- SF dune queries\n",
        "Might add more metadata to create different aggregations but not necessary for now.\n",
        "    - wallel labels that come from lk_addresses in the kitchen\n",
        "\n",
        "args:\n",
        "    token_address: ENS token address - comment in the query to exclude/include by excluding parameters\n",
        "\n",
        "returns:\n",
        "    financials.csv: historical financial data for ENS\n",
        "\"\"\"\n",
        "\n",
        "# create params for query\n",
        "parameters = {\n",
        "    'token_address': ENSConfig.ENS_TOKEN_ADDRESS\n",
        "}\n",
        "\n",
        "# Get data from dune query\n",
        "df_financials = spice_query_id(\n",
        "    query_id=ENSConfig.DUNE_QID_EXTRACT_SF_ENS_FINANCIALS_PER_WALLET,\n",
        "    api_key=ENSConfig.DUNE_API_KEY,\n",
        "    parameters=parameters,\n",
        "    refresh=True,\n",
        ")\n",
        "\n",
        "print(\"Financial data obtained from Dune.\")\n",
        "\n",
        "# period/year data comes with hh:mm:ss:... - convert to date/year only\n",
        "df_financials['year'] = pd.to_datetime(df_financials['year'])\n",
        "df_financials['year'] = df_financials['year'].dt.year\n",
        "\n",
        "df_financials['period'] = pd.to_datetime(df_financials['period'])\n",
        "df_financials['period'] = df_financials['period'].dt.date\n",
        "\n",
        "# Export results\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.FINANCIALS_CSV}...\")\n",
        "df_financials.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.FINANCIALS_CSV}\", index=False)\n",
        "print(\"\\nExport complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DPE2r4zDPaT"
      },
      "source": [
        "## ens dao holdings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPvfkhEUDPaU"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fetches ENS DAO (excl. Endowment) holdings extractor query <- SF dune queries\n",
        "\n",
        "args:\n",
        "    query params: addresses coming from lk_Addresses, custom_date\n",
        "\n",
        "returns:\n",
        "    financials.csv: historical financial data for ENS\n",
        "\"\"\"\n",
        "\n",
        "# Fetch addresses from Google Sheet\n",
        "json_lk_addresses = etl_gen_df_from_gsheet(gc, ENSConfig.WORKBOOK_URL, ENSConfig.LK_ADDRESSES_TAB)\n",
        "\n",
        "# get only the addresses - remember to lower for correct matching later\n",
        "ens_addresses = [\n",
        "    address.get('address').lower() for address in json_lk_addresses\n",
        "]\n",
        "\n",
        "ens_addresses = \",\".join(ens_addresses)\n",
        "\n",
        "# create params for query\n",
        "custom_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
        "parameters = {\n",
        "    'ens_addresses': ens_addresses,\n",
        "    'custom_date': custom_date\n",
        "}\n",
        "\n",
        "# Get data from dune query\n",
        "df_holdings = spice_query_id(\n",
        "    query_id=ENSConfig.DUNE_QID_EXTRACT_ENS_DAO_HOLDINGS,\n",
        "    api_key=ENSConfig.DUNE_API_KEY,\n",
        "    parameters=parameters,\n",
        "    refresh=True,\n",
        ")\n",
        "\n",
        "print(\"Holdings data obtained from Dune.\")\n",
        "\n",
        "# period data comes with hh:mm:ss:... - convert to date only\n",
        "df_holdings['day'] = pd.to_datetime(df_holdings['day'])\n",
        "df_holdings['day'] = df_holdings['day'].dt.date\n",
        "\n",
        "# Export results\n",
        "print(f\"\\nExporting results to {ENSConfig.DATA_DIR}{ENSConfig.HOLDINGS_CSV}...\")\n",
        "df_holdings.to_csv(f\"{ENSConfig.DATA_DIR}{ENSConfig.HOLDINGS_CSV}\", index=False)\n",
        "print(\"\\nExport complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [standalone] yields for review"
      ],
      "metadata": {
        "id": "UbCj9Xj_DQT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaultsfyi"
      ],
      "metadata": {
        "id": "l03JIRkrKcDA",
        "outputId": "ea4a9fde-0a7a-416f-98e4-e1cf6d5baf1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaultsfyi\n",
            "  Downloading vaultsfyi-1.1.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.11/dist-packages (from vaultsfyi) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->vaultsfyi) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->vaultsfyi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->vaultsfyi) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->vaultsfyi) (2025.7.14)\n",
            "Downloading vaultsfyi-1.1.0-py3-none-any.whl (8.5 kB)\n",
            "Installing collected packages: vaultsfyi\n",
            "Successfully installed vaultsfyi-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime\n",
        "from vaultsfyi import VaultsSdk\n",
        "\n",
        "# ====================================================================================\n",
        "# USER CONFIGURATION\n",
        "# ====================================================================================\n",
        "\n",
        "# vaults.fyi API Key â€“ please don't stress the execution button as we might be left without credit\n",
        "client = VaultsSdk(api_key=\"mUecsmXr58GvFdjCa4Pm0BZufmnb0Rj7FnVmL56R5K4\")\n",
        "\n",
        "# ====================================================================================\n",
        "# VAULTS CONFIGURATION\n",
        "# ====================================================================================\n",
        "\n",
        "vaults = [\n",
        "    {\n",
        "        'label': 'Aave v3 USDC',\n",
        "        'address': '0x98C23E9d8f34FEFb1B7BD6a91B7FF122F4e16F5c',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'USDC',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "    {\n",
        "        'label': 'Compound v3 USDC',\n",
        "        'address': '0xc3d688B66703497DAA19211EEdff47f25384cdc3',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'USDC',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "    {\n",
        "        'label': 'Aave v3 DAI',\n",
        "        'address': '0x018008bfb33d285247A21d44E50697654f754e63',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'DAI',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "    {\n",
        "        'label': 'Savings DAI (sDAI)',\n",
        "        'address': '0x83F20F44975D03b1b09e64809B757c47f942BEeA',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'DAI',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "    {\n",
        "        'label': 'Savings USDS',\n",
        "        'address': '0xa3931d71877C0E7a3148CB7Eb4463524FEc27fbD',\n",
        "        'network': 'mainnet',\n",
        "        'asset': 'USDS',\n",
        "        'allocation': 'stable'\n",
        "    },\n",
        "]\n",
        "\n",
        "# ====================================================================================\n",
        "# GET HISTORICAL DATA\n",
        "# ====================================================================================\n",
        "\n",
        "historical_data = []\n",
        "\n",
        "for vault in vaults:\n",
        "    vault_historical_data_tmp = client.get_vault_historical_data(\n",
        "        network = vault['network'],\n",
        "        vault_address = vault['address'],\n",
        "        page = 0,\n",
        "        perPage = 1000,\n",
        "        apyInterval = '1day',\n",
        "        granularity = '1day'\n",
        "        # fromTimestamp: 1640995200,\n",
        "        # toTimestamp: 1672531200\n",
        "    )\n",
        "\n",
        "    for record in vault_historical_data_tmp['data']:\n",
        "        vault_historical_data = {\n",
        "            'label': vault['label'],\n",
        "            'asset': vault['asset'],\n",
        "            'allocation': vault['allocation'],\n",
        "            'timestamp': record['timestamp'],\n",
        "            'apy_base': record['apy']['base'],\n",
        "            'apy_reward': record['apy']['reward'],\n",
        "            'apy_total': record['apy']['total']\n",
        "        }\n",
        "\n",
        "        historical_data.append(vault_historical_data)\n",
        "\n",
        "df = pd.DataFrame.from_records(historical_data)\n",
        "\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], unit = 's')\n",
        "\n",
        "df['month'] = df['timestamp'].dt.to_period('M').dt.to_timestamp()\n",
        "df_monthly = df.drop('timestamp', axis = 1).groupby(\n",
        "    ['month', 'allocation', 'asset', 'label'],\n",
        "    as_index=False\n",
        ").mean()\n",
        "\n",
        "df_monthly.to_csv('monthly_yields.csv')\n",
        "\n",
        "df['year'] = df['timestamp'].dt.to_period('Y').dt.to_timestamp()\n",
        "df_yearly = df.drop('timestamp', axis = 1).groupby(\n",
        "    ['year', 'allocation', 'asset', 'label'],\n",
        "    as_index=False\n",
        ").mean()\n",
        "\n",
        "df_yearly.to_csv('yearly_yields.csv')"
      ],
      "metadata": {
        "id": "h51HRE41DXMd"
      },
      "execution_count": 76,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "kpk-general",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}